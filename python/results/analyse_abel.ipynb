{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Dados\\\\OneDrive\\\\Doutorado\\\\workspace\\\\bc-playground\\\\python\\\\results',\n",
       " 'D:\\\\Programas\\\\Anaconda3\\\\python37.zip',\n",
       " 'D:\\\\Programas\\\\Anaconda3\\\\DLLs',\n",
       " 'D:\\\\Programas\\\\Anaconda3\\\\lib',\n",
       " 'D:\\\\Programas\\\\Anaconda3',\n",
       " '',\n",
       " 'D:\\\\Programas\\\\Anaconda3\\\\lib\\\\site-packages',\n",
       " 'D:\\\\Programas\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32',\n",
       " 'D:\\\\Programas\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'D:\\\\Programas\\\\Anaconda3\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'D:\\\\Programas\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\thiag\\\\.ipython']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lib.util'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3d9991789f4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgetbase_dir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mencrypt\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mencrypt_data_in_memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmybloom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbloomutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjaccard_coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lib.util'"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from lib.util.env import getbase_dir\n",
    "from encrypt import encrypt_data_in_memory\n",
    "from lib.mybloom.bloomutil import jaccard_coefficient\n",
    "from splitting_bf.evaluation import split_bf #change method\n",
    "from splitting_bf.evaluation import simulated_sbf_protocol\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "#isTrueMatch(gold_standard_dblp_acm,'journals/sigmod/Dogac02',507340)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metodos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodos de simulacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def split_ds(df,n):\n",
    "    retorno = []\n",
    "    for row in df:\n",
    "        retorno.append([row[0],row[1],split_bf(row[1],n),n])\n",
    "    return pd.DataFrame(retorno, columns = ['id' , 'bf', 'sbf' , 'n_sbf'])\n",
    "\n",
    "\n",
    "def calculate_sbf_similarity(dfa,dfb,split_pos=0):\n",
    "    \"\"\"\n",
    "    O split_sim e apenas o do split\n",
    "    o sbf_sim e de tudo\n",
    "\n",
    "    :param dfa:\n",
    "    :param dfb:\n",
    "    :param split_pos:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for indexa, rowa in dfa.iterrows():\n",
    "        for indexb, rowb in dfb.iterrows():\n",
    "            full_bf_sim = jaccard_coefficient(rowa[1],rowb[1])\n",
    "            # print(rowa[2])\n",
    "            split_sim = jaccard_coefficient(rowa[2][split_pos],rowb[2][split_pos])\n",
    "\n",
    "            soma = 0\n",
    "            for i in range(0,len(rowa[2])):\n",
    "                soma += jaccard_coefficient(rowa[2][i], rowb[2][i])\n",
    "\n",
    "            result.append({'id_a': rowa[0], 'id_b': rowb[0], 'full_bf': full_bf_sim, 'split_sim': split_sim, 'sbf_sim': soma/len(rowa[2]), 'splits': len(rowa[2])})\n",
    "\n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "\n",
    "def private_calculate_precision_recall(zdf,technique):\n",
    "    clean_r = []\n",
    "    for index, row in zdf.iterrows():\n",
    "        # if count % 100 == 0:\n",
    "        #     print(count)\n",
    "        # count += 1\n",
    "\n",
    "        # id_max = zdf[(zdf['id_a'] == row['id_a']) & (zdf['id_b'] == row['id_b'])]['sbf_sim'].idxmax()\n",
    "        id_max_a = zdf[(zdf['id_a'] == row['id_a'])][technique].idxmax()\n",
    "        id_max_b = zdf[(zdf['id_b'] == row['id_b'])][technique].idxmax()\n",
    "\n",
    "        if (id_max_a == id_max_b) and (id_max_a == index):\n",
    "            # print(row)\n",
    "            rp = {'id_a': row['id_a'], 'id_b': row['id_b'], 'sbf_sim': row['sbf_sim'], 'bf_sim': row['bf_sim'],\n",
    "                  'sbf_stat': row['sbf_stat'],'bf_stat': row['bf_stat']}\n",
    "            clean_r.append(rp)\n",
    "\n",
    "    return pd.DataFrame(clean_r)\n",
    "\n",
    "\n",
    "    zdf = x_final\n",
    "    gs = gs_dict\n",
    "    for a in zdf.alfa.unique():\n",
    "        max_p_bf = -1\n",
    "        max_r_bf = -1\n",
    "        for e in zdf.beta_error.unique():\n",
    "            for s in zdf.sbf_splits.unique():\n",
    "                # quociente full bf\n",
    "                clean_bf = zdf[(zdf.alfa == a) & (zdf.beta_error == e) & (zdf.sbf_splits == s)]\n",
    "                qp_bf = len(clean_bf[clean_bf.bf_stat == 'FM']) + len(clean_bf[clean_bf.bf_stat == 'TM'])\n",
    "                if qp_bf != 0:\n",
    "                    p_bf = len(clean_bf[clean_bf.bf_stat == 'TM']) / qp_bf\n",
    "                else:\n",
    "                    print('aqui')\n",
    "                    p_bf = 0\n",
    "\n",
    "                r_bf = len(clean_bf[clean_bf.bf_stat == 'TM']) / len(gs)\n",
    "                max_p_bf = max(max_p_bf,p_bf)\n",
    "                max_r_bf = max(max_r_bf,r_bf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodos de plotagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_line_metric(dfm, title, ds='dblp_acm', dir='sbf_03'):\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    sns.lineplot(data=pf, x='threshold_alfa', y='vals', hue='bf_type',\n",
    "                 linewidth=2.5, dashes=[(0, 0), (2, 2)])\n",
    "    # sns.barplot(data=pf, x='threshold_alfa', y='vals', hue='cols',\n",
    "    #             linewidth=2.5)\n",
    "    # palette = \"tab10\"\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.grid('on')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    fig.savefig(file)\n",
    "    file = getbase_dir(['results', dir, ds + title + '.png'])\n",
    "\n",
    "\n",
    "def plot_metric(df,metric='f1'):\n",
    "    \"\"\"\n",
    "\n",
    "    :param df:\n",
    "    :param metric: recall, precision and f1 (default)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # global fig, ax, y, x\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    sns.barplot(data=df, x='alfa', y=metric+'_sbf',\n",
    "                capsize=.2, color='gray')\n",
    "    # ax2 = ax.twinx()\n",
    "    y = []\n",
    "    for x in df.alfa.unique():\n",
    "        y.append(df[df.alfa == x][metric+'_bf_full'].max())\n",
    "    ax.plot(ax.get_xticks(), y, color='red',\n",
    "            linestyle='--', linewidth=3, label='full_bf')\n",
    "    ax.grid('on')\n",
    "    # ax2.grid(False)\n",
    "    # plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    plt.clf()\n",
    "\n",
    "def plot_all_metrics(df,ds='dblp-acm'):\n",
    "    \"\"\"\n",
    "\n",
    "    :param df:\n",
    "    :param metric: recall, precision and f1 (default)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # global fig, ax, y, x\n",
    "    fig, axs = plt.subplots(figsize=(12, 5), ncols=3)\n",
    "    metrics = ['precision', 'recall', 'f1']\n",
    "    for i in range(0, len(axs)):\n",
    "        ax = axs[i]\n",
    "        metric = metrics[i]\n",
    "        sns.barplot(data=df, x='alfa', y=metrics[i] + '_sbf',\n",
    "                    capsize=.1, color='skyblue', alpha=0.8 ,\n",
    "                    ax=ax)\n",
    "        # sns.barplot(data=df, x='alfa', y=metrics[i] + '_sbf',\n",
    "        #             capsize=.2, ax=ax)\n",
    "\n",
    "        ax.set_title(metric)\n",
    "\n",
    "        y = []\n",
    "        for x in df.alfa.unique():\n",
    "            y.append(df[df.alfa == x][metrics[i] + '_bf_full'].mean())\n",
    "\n",
    "        ax.plot(ax.get_xticks(), y, color='red',\n",
    "                linestyle='--', linewidth=2, label='full_bf')\n",
    "        ax.grid('on')\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.set_xlabel(r'$\\alpha$')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    plt.clf()\n",
    "    file = getbase_dir(['results', 'abel_01']) + 'plot_all_metrics_considering_alfas_' + ds + '.png'\n",
    "    fig.savefig(file, dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## variaveis de ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "gold_standard_dblp_acm = pd.read_csv(getbase_dir(['Datasets', 'leipzig_dblp_acm']) + 'DBLP-ACM_perfectMapping.csv',\n",
    "                                         sep=',')\n",
    "gs_dict = {}\n",
    "for indexa, row in gold_standard_dblp_acm.iterrows():\n",
    "    gs_dict[str(row[0])+str(row[1])] = True\n",
    "\n",
    "del gold_standard_dblp_acm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcular similaridade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Carregar variaveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "acm = pd.read_csv(getbase_dir(['Datasets', 'leipzig_dblp_acm']) + 'ACM.csv', sep=',')\n",
    "dblp = pd.read_csv(getbase_dir(['Datasets', 'leipzig_dblp_acm']) + 'DBLP2.csv', sep=',', encoding='latin')\n",
    "\n",
    "eacm = encrypt_data_in_memory(acm, [1, 2, 3, 4], 1024)\n",
    "edblp = encrypt_data_in_memory(dblp, [1, 2, 3, 4], 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computar similaridades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "    splits_lenght = [3 , 4 , 5 , 6 , 7 , 8]\n",
    "    similarity = []\n",
    "\n",
    "    for s in splits_lenght:\n",
    "        print(s)\n",
    "        #df_acm = split_ds(eacm[0:10], s)\n",
    "        #df_dblp = split_ds(edblp[0:10], s)\n",
    "        df_acm = split_ds(eacm, s)\n",
    "        df_dblp = split_ds(edblp, s)\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        z = calculate_sbf_similarity(df_dblp,df_acm)\n",
    "        print(\"\\t %s seconds\" % (time.time() - start_time))\n",
    "        if len(similarity) == 0:\n",
    "            similarity = z\n",
    "        else:\n",
    "            similarity = pd.concat([similarity, z])\n",
    "\n",
    "    del df_acm\n",
    "    del df_dblp\n",
    "\n",
    "    similarity.to_csv(getbase_dir(['results', 'abel_01']) + 'dblp_acm_sim.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simular protocolo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caregar similaridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1921.3882446289062\n"
     ]
    }
   ],
   "source": [
    "similarity = pd.read_csv(getbase_dir(['results', 'abel_01']) + 'dblp_acm_sim.csv')\n",
    "# z = similarity[(similarity.id_a=='conf/vldb/PoosalaI96') & (similarity.id_b==304587)]\n",
    "print(similarity.memory_usage(index=True).sum()/1024/1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ajuste nos dados se necessario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# len(similarity)\n",
    "    # len(similarity[similarity.splits.isin([3,5,8])])\n",
    "len(similarity)\n",
    "s = similarity[similarity['splits'].isin([8, 16,32,64,128])]\n",
    "len(s)\n",
    "del similarity\n",
    "similarity = s\n",
    "del s\n",
    "del indexa\n",
    "del row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del acm\n",
    "del dblp\n",
    "del eacm\n",
    "del edblp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulação do protocolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "chunks = np.array_split(similarity, 6)\n",
    "del similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== chunk: 0\n",
      "1524.9114990234375\n",
      "=== 0.5\n",
      "\t Poll criado\n"
     ]
    }
   ],
   "source": [
    "# alfas_t = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "#v = 'alfa1'\n",
    "v = 'alfa5e'\n",
    "alfas_t = [.5]\n",
    "x_final = []\n",
    "errors_a5 = [.001,.01,.025,.5,.15,.2,.25,.3,.37]\n",
    "# from multiprocessing.pool import ThreadPool\n",
    "# pool = ThreadPool(processes=8)\n",
    "pool = mp.Pool(processes=4)\n",
    "\n",
    "for c in range(0,len(chunks)):\n",
    "    sim_chunk = chunks.pop(0)\n",
    "    \n",
    "    print(\"=========== chunk: \" + str(c))\n",
    "    \n",
    "    total = 0\n",
    "    for k in range(0,len(chunks)):\n",
    "        total += sim_chunk.memory_usage(index=True).sum()/1024/1024\n",
    "    print(total)\n",
    "    \n",
    "    for alfa in alfas_t:\n",
    "        print(\"=== \" + str(alfa))\n",
    "        # x.to_csv('x.csv',index=False)\n",
    "        # x = pd.read_csv('x.csv')\n",
    "\n",
    "        # stand alone\n",
    "        # x = simulated_sbf_protocol(similarity, gs_dict, alfa , error= 0.1)\n",
    "        # para utilizar  a simulaçao\n",
    "\n",
    "        print(\"\\t Poll criado\")\n",
    "\n",
    "        # results = [pool.imap(simulated_sbf_protocol,\n",
    "        results = [pool.apply_async(simulated_sbf_protocol,\n",
    "                                    args=(sim_chunk, gs_dict, alfa),\n",
    "                                    # args=(similarity, gs_dict, alfa),\n",
    "#                                     kwds={'error': e}) for e in np.arange(0.01, .2, 0.04)\n",
    "                                    kwds={'error': e}) for e in errors_a5\n",
    "                                    # kwds={'error': e}) for e in np.arange(0.01, .4, 0.9)\n",
    "                                    #kwds={'error': e}) for e in np.arange(0.01, .4, 0.07)\n",
    "                   ]\n",
    "\n",
    "        output = [p.get() for p in results]\n",
    "\n",
    "        x = output[0]\n",
    "        for pdf in output[1:]:\n",
    "            x = x.append(pdf, ignore_index=True)\n",
    "\n",
    "        print(\"\\t Resultados capturados\")\n",
    "        # salva os resultados intermediarops\n",
    "#         x.to_csv(\n",
    "#             getbase_dir(['results', 'abel_01']) + 'intermediate_dblp_acm_'+v+'_chunk' + str(c) + '_' + str(alfa) + '.csv')\n",
    "#         print(\"\\t Resultados salvos\")\n",
    "    del sim_chunk\n",
    "    \n",
    "pool.close()\n",
    "#         if len(x_final) == 0:\n",
    "#             x_final = x\n",
    "#         else:\n",
    "#             x_final = pd.concat([x_final, x])\n",
    "\n",
    "del chunks, output\n",
    "del pool\n",
    "del pd\n",
    "del results\n",
    "#### fora do for\n",
    "x_final.to_csv(getbase_dir(['results', 'abel_01']) + 'dblp_acm_x_final_'+v+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# recuperar pelos intermediarios\n",
    "x_final = []\n",
    "for alfa in alfas_t:\n",
    "    for c in range(1,13): \n",
    "        x = getbase_dir(['results', 'abel_01']) + 'intermediate_dblp_acm_'+v+'_chunk' + str(c) + '_' + str(alfa) + '.csv')\n",
    "        if len(x_final) == 0:\n",
    "            x_final = x\n",
    "        else:\n",
    "            x_final = pd.concat([x_final, x])\n",
    "\n",
    "x_final.to_csv(getbase_dir(['results', 'abel_01']) + 'dblp_acm_x_final_'+v+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salvandos os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def calculate_precision_recall(zdf, gs, ds_name , full_bf_len=1024):\n",
    "\n",
    "    # zdf = fdf[fdf.abel_1st_s == True]\n",
    "    count = 0\n",
    "\n",
    "    saida = []\n",
    "    for a in zdf.alfa.unique():\n",
    "        max_p_bf = -1\n",
    "        max_r_bf = -1\n",
    "        for e in zdf.beta_error.unique():\n",
    "            for s in zdf.sbf_splits.unique():\n",
    "                # quociente full bf'\n",
    "                clean_bf = zdf[(zdf.alfa == a) & (zdf.beta_error == e) & (zdf.sbf_splits == s)]\n",
    "                qp_bf = len(clean_bf[clean_bf.bf_stat == 'FM']) + len(clean_bf[clean_bf.bf_stat == 'TM'])\n",
    "                if qp_bf != 0:\n",
    "                    p_bf = len(clean_bf[clean_bf.bf_stat == 'TM']) / qp_bf\n",
    "                else:\n",
    "                    print('aqui ')\n",
    "                    p_bf = 0\n",
    "\n",
    "                r_bf = len(clean_bf[clean_bf.bf_stat == 'TM']) / len(gs)\n",
    "                max_p_bf = max(max_p_bf, p_bf)\n",
    "                max_r_bf = max(max_r_bf, r_bf)\n",
    "\n",
    "\n",
    "        for e in zdf.beta_error.unique():\n",
    "            for s in zdf.sbf_splits.unique():\n",
    "                #Colocar true no 1st_la\n",
    "                tdf = zdf[(zdf.abel_1st_s == True ) & (zdf.alfa == a) & (zdf.beta_error == e) & (zdf.sbf_splits == s)]\n",
    "                clean_sbf = tdf\n",
    "\n",
    "                # cociente precision\n",
    "                qp_spf = len(clean_sbf[clean_sbf.sbf_stat == 'FM']) + len(clean_sbf[clean_sbf.sbf_stat == 'TM'])\n",
    "                if qp_spf != 0:\n",
    "                    p_sbf = len(clean_sbf[clean_sbf.sbf_stat == 'TM']) / qp_spf\n",
    "                else:\n",
    "                    p_sbf = 0\n",
    "\n",
    "                r_sbf = len(clean_sbf[clean_sbf.sbf_stat == 'TM']) / len(gs)\n",
    "\n",
    "                saida.append([ds_name, s, full_bf_len, a, e, p_sbf, r_sbf, max_p_bf, max_r_bf])\n",
    "\n",
    "    return pd.DataFrame(saida, columns = ['ds_name', 'sbf_splits' , 'bf_len' ,\n",
    "                                          'alfa' , 'beta_error', 'precision_sbf' ,\n",
    "                                          'recall_sbf' , 'precision_bf_full' , 'recall_bf_full' ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "salvando os resultados finais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "final_result = calculate_precision_recall(x_final, gs_dict, 'dblp_acm')\n",
    "final_result['f1_bf_full'] = 2 * ((final_result['precision_bf_full'] * final_result['recall_bf_full']) / (final_result['precision_bf_full'] + final_result['recall_bf_full']))\n",
    "final_result['f1_sbf'] = 2 * ((final_result['precision_sbf'] * final_result['recall_sbf']) / (final_result['precision_sbf'] + final_result['recall_sbf']))\n",
    "final_result['ls'] = (final_result.bf_len / final_result.sbf_splits) / final_result.bf_len\n",
    "final_result.to_csv(getbase_dir(['results', 'abel_01']) + 'dblp_acm_final_result_'+v+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graficos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### carregandos os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#v = 'b1' #old computado errado\n",
    "v = 'alfa5'\n",
    "\n",
    "rf = 'dblp_acm_final_result_'+v+'.csv'\n",
    "xf = 'dblp_acm_x_final_'+v+'.csv'\n",
    "\n",
    "x_final = pd.read_csv(getbase_dir(['results', 'abel_01']) + xf)\n",
    "final_result = pd.read_csv(getbase_dir(['results', 'abel_01']) + rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def calculate_precision_recall(zdf, gs, ds_name , full_bf_len=1024):\n",
    "\n",
    "    # zdf = fdf[fdf.abel_1st_s == True]\n",
    "    count = 0\n",
    "\n",
    "    saida = []\n",
    "    for a in zdf.alfa.unique():\n",
    "        max_p_bf = -1\n",
    "        max_r_bf = -1\n",
    "        for e in zdf.beta_error.unique():\n",
    "            for s in zdf.sbf_splits.unique():\n",
    "                # quociente full bf'\n",
    "                clean_bf = zdf[(zdf.alfa == a) & (zdf.beta_error == e) & (zdf.sbf_splits == s)]\n",
    "                \n",
    "                TP = len(clean_bf[clean_bf.bf_stat == 'TM'])\n",
    "                #FALSE POSITIVE\n",
    "                FP = len(clean_bf[clean_bf.bf_stat == 'FM'])\n",
    "                #FALSE NEGATIVE\n",
    "                FN = len(gs) - TP\n",
    "                \n",
    "                qp_spf = TP + FP\n",
    "                if qp_spf != 0:\n",
    "                    p_bf = TP / qp_spf\n",
    "                else:\n",
    "                    p_sbf = 0\n",
    "                \n",
    "                r_bf = TP / (TP + FN)\n",
    "                \n",
    "                max_p_bf = max(max_p_bf, p_bf)\n",
    "                max_r_bf = max(max_r_bf, r_bf)\n",
    "#                 print(max_r_bf)\n",
    "        \n",
    "        del clean_bf\n",
    "        del p_bf\n",
    "        del r_bf\n",
    "\n",
    "\n",
    "        for e in zdf.beta_error.unique():\n",
    "            for s in zdf.sbf_splits.unique(): \n",
    "                \n",
    "                #Colocar true no 1st_la\n",
    "                clean_sbf = zdf[(zdf.abel_1st_s == True ) & (zdf.alfa == a) & (zdf.beta_error == e) & (zdf.sbf_splits == s)]\n",
    "                \n",
    "                #TRUE POSITIVE\n",
    "                TP = len(clean_sbf[clean_sbf.sbf_stat == 'TM'])\n",
    "                #FALSE POSITIVE\n",
    "                FP = len(clean_sbf[clean_sbf.sbf_stat == 'FM'])\n",
    "                #FALSE NEGATIVE\n",
    "                FN = len(gs) - TP               \n",
    "                \n",
    "                # cociente precision\n",
    "                qp_spf = TP + FP\n",
    "                if qp_spf != 0:\n",
    "                    p_sbf = TP / qp_spf\n",
    "                else:\n",
    "                    p_sbf = 0\n",
    "\n",
    "                r_sbf = TP / (TP + FN)\n",
    "\n",
    "                saida.append([ds_name, s, full_bf_len, a, e, p_sbf, r_sbf, max_p_bf, max_r_bf])\n",
    "\n",
    "    return pd.DataFrame(saida, columns = ['ds_name', 'sbf_splits' , 'bf_len' ,\n",
    "                                          'alfa' , 'beta_error', 'precision_sbf' ,\n",
    "                                          'recall_sbf' , 'precision_bf_full' , 'recall_bf_full' ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "final_result = calculate_precision_recall(x_final,gs_dict,'dblp-acm')\n",
    "final_result['f1_bf_full'] = 2 * ((final_result['precision_bf_full'] * final_result['recall_bf_full']) / (final_result['precision_bf_full'] + final_result['recall_bf_full']))\n",
    "final_result['f1_sbf'] = 2 * ((final_result['precision_sbf'] * final_result['recall_sbf']) / (final_result['precision_sbf'] + final_result['recall_sbf']))\n",
    "final_result['ls'] = (final_result.bf_len / final_result.sbf_splits) / final_result.bf_len\n",
    "final_result.to_csv(getbase_dir(['results', 'abel_01']) + 'dblp_acm_final_result_alfa5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ajustes nos dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "final_result = final_result[final_result.sbf_splits != max(final_result.sbf_splits.unique())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figura 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mericas individualizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plot_metric(final_result, metric='f1')\n",
    "plot_metric(final_result,metric='precision')\n",
    "plot_metric(final_result, metric='recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas as metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plot_all_metrics(final_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "teste estatiscos da figura 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon , ttest_ind\n",
    "#  null hypothesis of identical average scores. (< 0.05)\n",
    "for metric in ['f1','precision','recall']:\n",
    "    y_bf = []\n",
    "    y_sbf = []\n",
    "    # metric = 'f1'\n",
    "    for x in final_result.alfa.unique():\n",
    "        y_bf.append(final_result[final_result.alfa == x][metric + '_bf_full'].mean())\n",
    "        y_sbf.append(final_result[final_result.alfa == x][metric + '_sbf'].median())\n",
    "    print(metric)\n",
    "        # print(wilcoxon(final_result[metric + '_bf_full'], final_result[metric + '_bf_full']))\n",
    "    print(ttest_ind(y_bf,y_sbf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figura 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metodo da plotagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_quality_considering_error(df,limiar,metric='f1'):\n",
    "\n",
    "    ldf = df[df.alfa == limiar].round(3)\n",
    "    ldf.ls = ldf.ls.astype(str) + '%'\n",
    "    # ldf['ls'] = (final_result.bf_len / final_result.sbf_splits) / final_result.bf_len\n",
    "    # ldf.sbf_splits = ldf.sbf_splits.astype(str)\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    # palette = dict(zip(ldf.sbf_splits.unique(), sns.color_palette()))\n",
    "    # palette.update({\"Total\": \"k\"})\n",
    "    sns.lineplot(data=ldf, x='beta_error', y=metric+'_sbf', hue=\"ls\")\n",
    "    y = []\n",
    "    for x in ax.get_xticks():\n",
    "        y.append(df[metric+'_bf_full'].max())\n",
    "    ax.plot(ax.get_xticks(), y, color='red',\n",
    "            linestyle='--', linewidth=3, label='Sine')\n",
    "    # sns.lineplot(data=ldf, x='beta_error', y='f1_sbf', hue=\"sbf_splits\", palette=palette)\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    plt.clf()\n",
    "\n",
    "def plot_all_quality_considering_error(df,limiar,ds='dblp-acm',pontos=[]):\n",
    "    \"\"\"\n",
    "\n",
    "    :param df:\n",
    "    :param limiar:\n",
    "    :param ds:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    ldf = df[df.alfa == limiar]\n",
    "\n",
    "    ldf['z'] = df.bf_len / df.sbf_splits\n",
    "    ldf['split_length'] = ldf.ls.round(3).astype(str) + '% '\n",
    "    ldf.split_length = ldf.split_length + '(' +ldf.z.astype(str) + ' bits)'\n",
    "    ldf['beta'] = limiar - ldf.beta_error\n",
    "    # min_x = ldf.beta.min()\n",
    "    # max_x = ldf.beta.max()\n",
    "    min_x = ldf.beta_error.min()\n",
    "    max_x = ldf.beta_error.max()\n",
    "\n",
    "    fig, axs = plt.subplots(figsize=(12, 5), ncols=3)\n",
    "    metrics = ['precision', 'recall', 'f1']\n",
    "    for i in range(0, len(axs)):\n",
    "        metric = metrics[i]\n",
    "\n",
    "        ax = axs[i]\n",
    "        ax.set_xlim(min_x,max_x)\n",
    "        # ax.set_xlim(max_x,min_x)\n",
    "        ax.set_title(r\"\" +metric + \" $\\\\alpha$ =\"+ str(limiar) )\n",
    "\n",
    "        g = sns.lineplot(data=ldf, x='beta_error', y=metric + '_sbf',\n",
    "                         hue=\"split_length\", ax=ax)\n",
    "        # g = sns.lineplot(data=ldf, x='beta', y=metric+'_sbf',\n",
    "        #                 hue=\"split_length\", ax=ax)\n",
    "\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.set_xlabel(r'error ($\\beta = \\alpha - error)$')\n",
    "\n",
    "        y = []\n",
    "        for x in ax.get_xticks():\n",
    "            y.append(ldf[metric+'_bf_full'].mean())\n",
    "\n",
    "        ax.plot(ax.get_xticks(), y, color='red',\n",
    "                linestyle='--', linewidth=2, label='full_bf')\n",
    "\n",
    "        #### errros\n",
    "        if len(pontos) != 0:\n",
    "            if metric != 'f1-':\n",
    "                cores = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan']\n",
    "                cc = 0\n",
    "                for vx in pontos.round(2).y:\n",
    "                    # ax.axvline(x=vx, linewidth=2, c=c.colors[cc], alpha=0.8)\n",
    "                    ax.axvline(x=vx, linewidth=10, c=cores[cc], alpha=0.2)\n",
    "                    cc+=1\n",
    "            # ax.scatter(pontos.x, pontos.y ,c=pontos.x, #s=scale, label=color,\n",
    "            #         alpha=0.8, edgecolors='none')\n",
    "\n",
    "            # ax.axhline(pontos.y, linewidth=2, c=pontos.x, alpha=0.8)\n",
    "\n",
    "\n",
    "        ax.grid(True)\n",
    "        if i == 1:\n",
    "            g.legend(loc='lower center', bbox_to_anchor= (0.5, -.45) ,\n",
    "                     borderaxespad=0, frameon=False,\n",
    "                     fontsize = 'medium', ncol=2 )\n",
    "        else:\n",
    "            ax.get_legend().remove()\n",
    "            # fontsize: int or float or {'xx-small', 'x-small', 'small', 'medium', 'large', 'x-large', 'xx-large'}\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    plt.clf()\n",
    "    if len(pontos) == 0:\n",
    "        file = getbase_dir(['results', 'abel_01']) + 'plot_all_quality_considering_error_'+ds+'_alfa_'+str(limiar)+'.png'\n",
    "    else:\n",
    "        file = getbase_dir(['results', 'abel_01']) + 'plot_all_quality_considering_error_' +ds+ '_alfa_' + str(limiar) + '_width_region.png'\n",
    "    fig.savefig(file,dpi=800)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo as regiões beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "a = -0.042876301194393125\n",
    "b = 3.2574724870013103\n",
    "\n",
    "fe1 = lambda x, a, b: a * np.log(b * x)\n",
    "mi = fe1(.99999,a,b)\n",
    "ma = fe1(.00001,a,b)\n",
    "#fe1 = lambda x: -np.log(x)\n",
    "#mi = fe1(.9999999999999)\n",
    "#ma = fe1(.0000000000001)\n",
    "\n",
    "normalize = lambda x,min,max:  (x - min) / (max - min)\n",
    "\n",
    "pontos = []\n",
    "for i in final_result.ls.unique():\n",
    "    # print(\"{} & {} & \\\\\\\\\".format(i,fe1(i,a,b)))\n",
    "    #n = normalize(fe1(i), mi, ma)\n",
    "    x = fe1(i,a,b)\n",
    "    n = normalize(x, mi, ma)\n",
    "    \n",
    "    pontos.append([i,n,x])\n",
    "    #print(\"{0:.3f} & {1:.2f} \\\\\\\\\".format(i, n))\n",
    "\n",
    "pontos = pd.DataFrame(pontos,columns=['x','y','z'])\n",
    "pontos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#plot_all_quality_considering_error(final_result, .5 ,pontos=pontos[:-1])\n",
    "#ldf = final_result[final_result.alfa==.5]\n",
    "#plot_all_quality_considering_error(ldf, .5 ,pontos=pontos)\n",
    "plot_all_quality_considering_error(final_result, .5 ,pontos=pontos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plota o restante dos graficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plot_all_quality_considering_error(final_result,.4)\n",
    "plot_all_quality_considering_error(final_result, .5)\n",
    "plot_all_quality_considering_error(final_result,.6)\n",
    "plot_all_quality_considering_error(final_result,.7)\n",
    "plot_all_quality_considering_error(final_result,.8)\n",
    "plot_all_quality_considering_error(final_result,.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "limiar = .5\n",
    "df =  x_final[(x_final.alfa == limiar)]\n",
    "df['beta'] = limiar - df.beta_error\n",
    "x = df[df.abel_1st_s == True].round(3).beta.astype(str)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "n_ds1=2617\n",
    "n_ds2=2294\n",
    "\n",
    "t = n_ds1 * n_ds2\n",
    "df['x'] = df[df.abel_1st_s == True].round(3).beta_error.astype(str)\n",
    "df['y'] = 1 / t\n",
    "df['y'] = 1\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "\n",
    "total = len(df[df.x == '0.33'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "# g = sns.catplot(x=\"x\", y=\"y\", hue=\"y\", kind=\"bar\", data=df)\n",
    "# for ax in g.axes.flat:\n",
    "#     ax.yaxis.set_major_formatter(PercentFormatter(1))\n",
    "# plt.show()\n",
    "# g = sns.catplot(x=\"x\", kind=\"count\", data=df)\n",
    "\n",
    "g = sns.countplot(x=\"x\", data=df)  # for Seaborn version 0.7 and more\n",
    "for p in g.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x() + p.get_width() / 2.,\n",
    "            height + 3,\n",
    "            '{:1.2f}'.format(height),\n",
    "            ha=\"center\")\n",
    "ax.grid(True)\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.clf()\n",
    "\n",
    "#file = getbase_dir(['results', 'abel_01']) + 'zzz_05_alfa_' + '.png'\n",
    "#fig.savefig(file, dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "    # final_result[(final_result.sbf_splits != 128) & (final_result.sbf_splits != 64)\n",
    "\n",
    "    n_ds1=2617\n",
    "    n_ds2=2294\n",
    "\n",
    "    t = n_ds1 * n_ds2\n",
    "    df['x'] = df[df.abel_1st_s == True].round(3).beta.astype(str)\n",
    "    df['y'] = 1 / t\n",
    "    df['y'] = 1\n",
    "    from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "\n",
    "    total = len(df[df.x == '0.33'])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    # g = sns.catplot(x=\"x\", y=\"y\", hue=\"y\", kind=\"bar\", data=df)\n",
    "    # for ax in g.axes.flat:\n",
    "    #     ax.yaxis.set_major_formatter(PercentFormatter(1))\n",
    "    # plt.show()\n",
    "    # g = sns.catplot(x=\"x\", kind=\"count\", data=df)\n",
    "\n",
    "    g = sns.countplot(x=\"x\", data=df)  # for Seaborn version 0.7 and more\n",
    "    for p in g.patches:\n",
    "        height = p.get_height()\n",
    "        ax.text(p.get_x() + p.get_width() / 2.,\n",
    "                height + 3,\n",
    "                '{:1.2f}'.format(height / total),\n",
    "                ha=\"center\")\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    plt.clf()\n",
    "\n",
    "    file = getbase_dir(['results', 'abel_01']) + 'zzz_05_alfa_' + '.png'\n",
    "    fig.savefig(file, dpi=400)\n",
    "\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "### scratch\n",
    "########################################################################\n",
    "def exec_01(n):\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    ids_a = [640999,190649, 615205, 375780, 375736]\n",
    "    ids_b = ['journals/sigmod/Winslett03','journals/sigmod/Kim94', 'conf/sigmod/BlakeleyD00', 'conf/sigmod/NazeriBO01', 'conf/sigmod/BorkarDS01' ]\n",
    "    for a in ids_a:\n",
    "        for b in ids_b:\n",
    "            print(isTrueMatchOriginal(gs, b, a))\n",
    "    print(time.time() - start_time)\n",
    "\n",
    "\n",
    "print(exec_01(1))\n",
    "\n",
    "gs =  gold_standard_dblp_acm.copy()\n",
    "\n",
    "gs.set_index(['idDBLP', 'ix'])\n",
    "\n",
    "ida = 'journals/sigmod/Winslett03'\n",
    "idb = 640999\n",
    "\n",
    "\n",
    "d = {}\n",
    "for indexa, row in gs.iterrows():\n",
    "    d[str(row[0])+str(row[1])] = True\n",
    "\n",
    "def isTrueMatch2(gs,ida,idb,base_a='idDBLP',base_b='idACM'):\n",
    "    try:\n",
    "        gs[str(ida)+str(idb)]\n",
    "        return True\n",
    "    except KeyError:\n",
    "        print\n",
    "        return False\n",
    "    #     # gs[(gs[base_a] == ida) & (gs[base_b] == idb)]\n",
    "    # if len(z) == 1:\n",
    "    #     return True\n",
    "    #\n",
    "    # return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
